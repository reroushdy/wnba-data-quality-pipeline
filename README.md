# WNBA Data Quality Pipeline ğŸ€

A Python-based **data quality and reporting pipeline** for WNBA player statistics.

This project extracts WNBA stats from a CSV (exported from MySQL), cleans and validates the data, detects statistical anomalies, generates visualizations, and produces a **PDF data quality report** with charts and issue summaries.

Itâ€™s designed as a realistic example of how a **Data Quality / QA Engineer** would structure a production-style analytics pipeline.

---

## âœ¨ Features

- ğŸ“¥ **Extraction**
  - Loads raw WNBA data from a CSV file (e.g., exported from MySQL Workbench).
  - Centralized loader with basic error handling.

- ğŸ§¹ **Cleaning (`src/clean.py`)**
  - Standardizes column names (snake_case, lowercase).
  - Trims whitespace from text fields.
  - Converts numeric-looking columns to numeric types.
  - Normalizes team names (e.g., `LVA` â†’ `Las Vegas Aces`).
  - Removes duplicate rows.
  - Handles missing values:
    - numeric â†’ column mean
    - text â†’ `"Unknown"`

- âœ… **Validation (`src/validate.py`)**
  - Checks required columns exist.
  - Validates numeric ranges (e.g., points_per_game, games_played).
  - Ensures teams and positions use allowed values.
  - Flags missing or â€œUnknownâ€ critical fields.
  - Detects likely duplicate players.
  - Returns a **DataFrame of validation issues** (with `severity`, `code`, and `message`).

- ğŸ” **Anomaly Detection (`src/detect_anomalies.py`)**
  - Uses the **IQR (Interquartile Range)** method to flag statistical outliers.
  - Focuses on `points_per_game` (customizable to other metrics).
  - Produces a filtered DataFrame of anomalous rows.

- ğŸ“Š **Visualization (`src/visualize.py`)**
  - Automatically detects suitable columns (e.g., `team` vs `team_name`, `points_per_game` vs `pts`).
  - Generates charts such as:
    - Average points per game by team.
    - Distribution of points per game.
    - Scatterplot highlighting anomalies (when available).
  - Saves PNG charts under `visuals/charts/`.

- ğŸ§¾ **PDF Reporting (`src/report.py`)**
  - Builds a multi-page **PDF data quality report** with:
    - Title/summary page.
    - Basic dataset stats.
    - Validation issues summary.
    - Anomalies summary.
    - Embedded charts from `visuals/charts/`.
  - Output saved under `reports/`.

---

## ğŸ“‚ Project Structure

```text
wnba_data_pipeline/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/          # Raw CSVs (e.g., wnba_raw_2024.csv)
â”‚   â”œâ”€â”€ cleaned/      # Cleaned exports (wnba_cleaned.csv)
â”‚   â”œâ”€â”€ anomalies/    # Anomaly CSV outputs
â”‚   â””â”€â”€ validated/    # Validation error logs (CSV)
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ data_dictionary.md   # Fields, types, and definitions
â”‚   â””â”€â”€ methodology.md       # Pipeline design & methodology
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ wnba_data_quality_report.pdf
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ clean.py             # Data cleaning logic
â”‚   â”œâ”€â”€ detect_anomalies.py  # IQR-based anomaly detection
â”‚   â”œâ”€â”€ extract.py           # CSV loading helpers
â”‚   â”œâ”€â”€ report.py            # PDF generation
â”‚   â”œâ”€â”€ validate.py          # Validation rules
â”‚   â””â”€â”€ visualize.py         # Plot generation
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_clean.py
â”‚   â”œâ”€â”€ test_validate.py
â”‚   â”œâ”€â”€ test_anomalies.py
â”‚   â”œâ”€â”€ test_extract.py
â”‚   â”œâ”€â”€ test_visualize.py
â”‚   â””â”€â”€ test_report.py
â”œâ”€â”€ visuals/
â”‚   â”œâ”€â”€ charts/      # Generated PNGs from the pipeline
â”‚   â””â”€â”€ examples/    # (Optional) Sample or saved visuals
â”œâ”€â”€ pipeline.py      # Main orchestration script
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

---

## ğŸ§ª Tests
Unit tests are implemented with pytest and cover:
	â€¢	Cleaning behavior (DataCleaner)
	â€¢	Validation rules (DataValidator)
	â€¢	Anomaly detection
	â€¢	Visualization outputs (basic existence, not aesthetics)
	â€¢	Extraction error handling
	â€¢	Report generation (PDF file exists)

---

## ğŸ”® Possible Enhancements (Future Work)
	â€¢	Add a data quality score (0â€“100) based on:
	â€¢	validation errors
	â€¢	warnings
	â€¢	anomaly counts
	â€¢	Support multiple seasons and trend analysis.
	â€¢	Add database integration (e.g., load cleaned data into MySQL/PostgreSQL).
	â€¢	Containerize with Docker for reproducible environments.
	â€¢	Build a dashboard using Streamlit / Power BI / Tableau.

---

## ğŸ¯ Why This Project Matters
This project demonstrates:
	â€¢	How a QA / Data Quality Engineer thinks about data robustness.
	â€¢	How to combine:
	â€¢	Python (pandas, matplotlib)
	â€¢	testing (pytest)
	â€¢	reporting (ReportLab)
	â€¢	and structured directories
	â€¢	How to turn raw sports data into an auditable, tested data product.
Itâ€™s suitable as a portfolio project to showcase skills in:
	â€¢	data quality engineering
	â€¢	Python scripting
	â€¢	data validation & anomaly detection
	â€¢	basic reporting & visualization pipelines

